{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "from InstructorEmbedding import INSTRUCTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "# Load the hkunlp/instructor-large model \n",
    "model = INSTRUCTOR('hkunlp/instructor-large')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the csv\n",
    "dataset_path = csv_file = '../asr/cv-valid-dev.csv'\n",
    "df = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hot words and their embeddings\n",
    "hot_words = [\"be careful\", \"destroy\", \"stranger\"]\n",
    "hot_word_embeddings = {word: model.encode([word]) for word in hot_words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate similarity\n",
    "def calculate_similarity(transcription):\n",
    "    sent_embedding = model.encode([transcription])\n",
    "    similarities = [cosine_similarity(sent_embedding, hot_word_embedding)[0] for hot_word_embedding in hot_word_embeddings.values()]\n",
    "    return max(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4076/4076 [01:19<00:00, 51.51it/s]\n"
     ]
    }
   ],
   "source": [
    "# Calculate similarity for each phrase in the dataset\n",
    "similarities = []\n",
    "for sent in tqdm(df[\"generated_text\"]):\n",
    "    similarity = calculate_similarity(sent)\n",
    "    similarities.append(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the similarity column to the dataset\n",
    "threshold = np.mean(similarities) # can be adjusted\n",
    "df[\"similarity\"] = [(similarity > threshold).item() for similarity in similarities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated dataset\n",
    "output_path = \"cv-valid-dev-with-similarity.csv\"\n",
    "df.to_csv(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
