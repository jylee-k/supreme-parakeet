{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the hkunlp/instructor-large model and tokenizer\n",
    "model_name = \"hkunlp/instructor-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Load the Common Voice dataset\n",
    "dataset_path = \"cv-valid-dev.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Define the hot words and their embeddings\n",
    "hot_words = [\"be careful\", \"destroy\", \"stranger\"]\n",
    "hot_word_embeddings = {word: tokenizer(word, return_tensors=\"pt\")[\"input_ids\"] for word in hot_words}\n",
    "\n",
    "# Define a function to calculate similarity\n",
    "def calculate_similarity(phrase):\n",
    "    phrase_embedding = tokenizer(phrase, return_tensors=\"pt\")[\"input_ids\"]\n",
    "    similarities = [torch.cosine_similarity(phrase_embedding, hot_word_embedding, dim=1).item() for hot_word_embedding in hot_word_embeddings.values()]\n",
    "    return max(similarities)\n",
    "\n",
    "# Calculate similarity for each phrase in the dataset\n",
    "similarities = []\n",
    "for phrase in tqdm(df[\"sentence\"]):\n",
    "    similarity = calculate_similarity(phrase)\n",
    "    similarities.append(similarity)\n",
    "\n",
    "# Add the similarity column to the dataset\n",
    "df[\"similarity\"] = [similarity > 0.7 for similarity in similarities]  # Adjust the threshold as needed\n",
    "\n",
    "# Save the updated dataset\n",
    "output_path = \"cv-valid-dev-with-similarity.csv\"\n",
    "df.to_csv(output_path, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
